# Use this file por persistence of configurations
# OpenAI API Configuration
OPENAI_API_KEY="sk-proj-1234567890"
OPENAI_BASE_URL=

# Other LLM Providers
ANTHROPIC_API_KEY=
OLLAMA=
PERPLEXITY_API_KEY=

# CTF Configuration
CTF_NAME=                # Name of the CTF challenge to run (e.g. "picoctf_static_flag")
CTF_CHALLENGE=           # Specific challenge name within the CTF to test
CTF_SUBNET="192.168.2.0/24"  # Network subnet for the CTF container
CTF_IP="192.168.2.100"   # IP address for the CTF container
CTF_INSIDE="true"        # Whether to conquer the CTF from within container

# CAI Agent Configuration
CAI_MODEL="qwen2.5:14b"  # Model to use for agents
CAI_DEBUG="1"            # Debug output level (0: Only tool outputs, 1: Verbose debug, 2: CLI debug)
CAI_BRIEF="false"        # Enable/disable brief output mode
CAI_MAX_TURNS="inf"      # Maximum number of turns for agent interactions
CAI_TRACING="true"       # Enable/disable OpenTelemetry tracing
CAI_AGENT_TYPE="one_tool_agent"  # Specify the agents to use (use "/agent" command to list all)
CAI_STATE="false"        # Enable/disable stateful mode for tracking network state and flags
CAI_ENV_CONTEXT="true"   # Add environment context, dirs and current env available

# Memory Configuration
CAI_MEMORY="false"       # Memory mode (episodic, semantic, all)
CAI_MEMORY_ONLINE="false"  # Enable/disable online memory mode
CAI_MEMORY_OFFLINE="false" # Enable/disable offline memory
CAI_MEMORY_ONLINE_INTERVAL="5"  # Number of turns between online memory updates

# Support Agent Configuration
CAI_PRICE_LIMIT="1"      # Price limit for the conversation in dollars
CAI_SUPPORT_MODEL="o3-mini"  # Model to use for the support agent
CAI_SUPPORT_INTERVAL="5"  # Number of turns between support agent executions

# Extensions Configuration
CAI_REPORT="ctf"         # Reporter mode (ctf, nis2, pentesting)